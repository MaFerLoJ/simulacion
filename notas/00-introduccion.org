#+TITLE: EST-24107: Simulación 
#+AUTHOR: Prof. Alfredo Garbuno Iñigo
#+EMAIL:  agarbuno@itam.mx
#+DATE: ~Introducción~ 
:LATEX_PROPERTIES:
#+SETUPFILE: ~/.emacs.d/templates/latex/handout.org
#+EXPORT_FILE_NAME: ../docs/00-introduction.pdf
:END:
#+STARTUP: showall
#+PROPERTY: header-args:R :session introduccion :exports both :results output org :tangle ../rscripts/00-introduccion.R :mkdirp yes :dir ../ :eval never
#+EXCLUDE_TAGS: toc latex

#+BEGIN_NOTES
*Profesor*: Alfredo Garbuno Iñigo | Otoño, 2023 | Introducción.\\
*Objetivo*: Estableceremos una idea general del alcance del curso. Esto nos llevará a encuadrar ciertos conceptos de simulación con el objetivo de cuantificar incertidumbre.\\
*Lectura recomendada*: El capítulo 1 de citet:Sullivan2015 brinda una introducción al área de cuantificación de incertidumbre (UQ). Los capítulos 1--4 de citet:Smith2013 tienen una bonita discusión (y un repaso) que sintoniza muy bien con lo expuesto en estas notas. El capítulo 1 de [[citet:&Hennig2022]] tiene una discusión interesante sobre el uso de simulación estocástica como proceso de cómputo numérico.
#+END_NOTES

#+begin_src R :exports none :results none
  ## Setup --------------------------------------------
  library(tibble)
  library(purrr)
  library(dplyr)
  library(tidyr)
  library(ggplot2)
  library(patchwork)
  library(scales)
  ## Cambia el default del tamaño de fuente 
  theme_set(theme_linedraw(base_size = 25))

  ## Cambia el número de decimales para mostrar
  options(digits = 4)
  ## Problemas con mi consola en Emacs
  options(pillar.subtle = FALSE)
  options(rlang_backtrace_on_error = "none")
  options(crayon.enabled = FALSE)

  ## Auxiliares para graficos
  color.itam  <- c("#00362b","#004a3b", "#00503f", "#006953", "#008367", "#009c7b", "#00b68f", NA)
  sin_lineas <- theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
  sin_leyenda <- theme(legend.position = "none")
  sin_ejes <- theme(axis.ticks = element_blank(), axis.text = element_blank())
#+end_src


* Contenido                                                             :toc:
:PROPERTIES:
:TOC:      :include all  :ignore this :depth 3
:END:
:CONTENTS:
- [[#motivación][Motivación]]
- [[#formulación][Formulación]]
- [[#notación][Notación]]
- [[#repaso-de-probabilidad][Repaso de probabilidad]]
- [[#conclusiones][Conclusiones]]
:END:

* Motivación 

Un curso típico de ~simulación estocástica~ hace énfasis en los /métodos de
inferencia estadística/ y /simulación de procesos estocásticos/. En contraste, este
curso tomará énfasis en el uso de herramientas con el objetivo de ~cuantificar
incertidumbre~. Este marco de trabajo nos permitirá dejar a futuro aplicaciones
de inferencia y procesos estocásticos.

#+REVEAL: split
Como modeladores matemáticos nos interesa ~abstraer y representar matemáticamente~
procesos o fenómenos.

#+REVEAL: split
Por ejemplo, nos interesa modelar el clima (procesos y
características atmosféricas en el largo plazo) lo cual podemos simplificar por
medio de ecuaciones diferenciales. Estas ecuaciones son un modelo matemático y
la única manera que tenemos de resolverlas es por medio de métodos numéricos (ver [[fig:gcm]]).

#+DOWNLOADED: screenshot @ 2022-06-25 22:24:50
#+caption: Imagen tomada de citep:Smith2013. 
#+attr_html: :width 700 :align center
#+attr_latex: :width .65\linewidth :placement [!htp]
#+name: fig:gcm
[[file:../images/20220625-222450_screenshot.png]]

#+BEGIN_NOTES
Por supuesto la representación matemática tiene sus limitaciones. Además, los
métodos numéricos que resuelven estos métodos son aproximaciones
computacionales. 
#+END_NOTES

#+REVEAL: split
El modelado de procesos nos permite tomar decisiones informadas. Por ejemplo, el
~modelado meteorológico~ nos permite tomar informar sobre ~eventos extremos~ como
huracanes (ver [[fig:forecast]]). 

#+DOWNLOADED: screenshot @ 2022-06-27 10:29:53
#+name: fig:forecast
#+caption: Imagen tomada de citep:Smith2013. 
#+attr_html: :width 1200 :align center
#+attr_latex: :width .65\linewidth :placement [!htp]
[[file:../images/20220627-102953_screenshot.png]]

#+REVEAL: split
Por medio de herramientas computacionales podemos generar una colección de
~situaciones ficticias~ y con esto estudiar un conjunto de ~escenarios hipotéticos~
(ver [[fig:forecast]]). Por ejemplo, nos interesa estudiar el ~comportamiento promedio~
y conocer la ~dispersión~ alrededor de este promedio. 

#+DOWNLOADED: screenshot @ 2022-06-27 10:57:29
#+caption: Imagen tomada de citep:Smith2013. 
#+attr_html: :width 700 :align center
#+attr_latex: :width .45\linewidth :placement [!htp]
[[file:../images/20220627-105729_screenshot.png]]

#+REVEAL: split
Una gran cantidad de problemas de modelado se reduce en poder resolver
~integrales de varias dimensiones~. Por ejemplo, en ~generación de gráficos por
computadora~ se tiene que resolver la ~ecuación de representación~ bajo distintos
escenarios (ver [[fig:rendering-eq]]).

#+DOWNLOADED: screenshot @ 2022-06-27 11:04:55
#+name: fig:rendering-eq
#+caption: Imagen tomada del material del curso [[http://15462.courses.cs.cmu.edu/fall2020/courseinfo][Gráficos por Computadora]] impartido en Carnegie Mellon. 
#+attr_html: :width 1200 :align center
#+attr_latex: :width .65\linewidth :placement [!htp]
[[file:../images/20220627-110455_screenshot.png]]

#+REVEAL: split
Por último, en aplicaciones como finanzas, telecomunicaciones o seguros nos
interesa estimar la probabilidad de ocurrencia de algún ~evento muy raro~
(probabilidad $\approx 10^{-3}$).

#+REVEAL: split
En resumen, los métodos que veremos en el curso serán su primera aproximación
para resolver estos problemas con ~énfasis en los algoritmos~ y la ~formulación
basada en probabilidad~.


* Formulación 

Abordaremos el tipo de problemas descrito anteriormente con un poco de notación
general.  Denotaremos por $z$ al resultado del fenómeno que nos interesa
modelar. Nuestro conocimiento científico nos permite modelar dicho fenómeno a
través de una abstracción la cual denotaremos por $f: X \rightarrow Z$ de tal forma que
\begin{align}
z \approx f(x) \,.
\end{align}
Esto nos permite hacer énfasis en que nuestro modelo matemático empata a la
realidad hasta ~cierto nivel de precisión~. Por otro lado, utilizamos el supuesto
que nuestro modelo matemático recibe /entradas/ especificas ($x$) que nos permiten
/reproducir/ los resultados con el modelo que hemos especificado.

#+REVEAL: split
Por ejemplo, consideremos el ~movimiento de los planetas alrededor del sol~ por
medio de las ecuaciones de movimiento de Newton. En dicho sistema denotamos
por $y \in \mathbb{R}^2$ el vector posición del planeta y por $p \in
\mathbb{R}^2$ el vector de
inercia. De tal forma que se satisface el sistema
\begin{gather}
\frac{\text{d}y}{\text{d}t} = \frac{p}{m}\,,\\
\frac{\text{d}y}{\text{d}t} = - \frac{k}{r^3} (y - y_\star)\,,
\end{gather}
donde $m$ denota la masa del planeta; $k$, la constante de gravitación por masa
planetaria y solar; y $r$ la distancia entre el planeta y el sol. En este
ejemplo, la función $f(x)$ es la solución del sistema de ecuaciones que nos da para
cada $x$. En este caso consideremos $x$ como el tiempo.

#+REVEAL: split
En nuestra caricatura anterior nos falta definir una colección de valores para
que nuestro modelo represente, por ejemplo, la trayectoria de la Tierra
alrededor del Sol. Para esto consideremos un ~vector de parámetros~ $\theta = (m,
k , y_\star) \in \mathbb{R}^3$.
Estos parámetros usualmente se ajustan de
acuerdo a algún criterio o procedimiento de inferencia. En este sentido nuestro
modelo lo podemos abstraer como
\begin{align}
z \approx f(x ; \theta) \,,
\end{align}
donde $f: X \times \Theta \rightarrow Z$ y pensamos que existe una configuración
de $\theta$ --- que muchas veces le llamamos $\theta^\star$ --- que acerca
proceso y que no podemos reducir por medio de un mejor modelo.
   
2. ~Incertidumbre epistémica~: se refiere a la incertidumbre derivada de nuestra
   simplificación del problema, nuestro estado de conocimiento o supuestos. En
   algunas ocasiones está asociada a los métodos numéricos con los que
   implementamos nuestros modelos. En otras, está asociada con los supuestos con
   lo que contamos para resolver un problema.

#+REVEAL: split
#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/numerics-epistemic.jpeg :exports results :results output graphics file
  genera_circulo <- function(n = 10){
    tibble(angulo = seq(0, 2*pi, length.out = n),
           x = sin(angulo), y = cos(angulo))
  }

  tibble(n = 2**c(3, 4, 8)) |>
    mutate(datos = map(n, genera_circulo)) |>
    unnest(datos) |>
    ggplot(aes(x, y)) + 
    geom_path(aes(group = n, lty = factor(n))) +
    coord_equal() + xlab(expression(x[1])) + ylab(expression(x[2])) + 
    sin_lineas + sin_leyenda + sin_ejes
#+end_src
#+caption: Aproximación a un circulo mediante una trayectoria discretizada.
#+attr_latex: :width .65\linewidth :placement [!htp]
#+RESULTS:
[[file:../images/numerics-epistemic.jpeg]]


#+REVEAL: split
Esta distinción nos ayuda a visualizar dos conceptos:
1. Identificar la necesidad de modelar incertidumbre en nuestros procesos. 
2. Identificar el origen de dicha incertidumbre.

#+REVEAL: split
Lamentablemente en la práctica, al momento de generar simulaciones, nos
olvidamos estas nociones y siempre es importante considerar las limitaciones de
nuestros modelos para representar correctamente la realidad.

#+REVEAL: split
Ahora, la pregunta natural es ¿cómo modelamos la incertidumbre? En este curso (y
en general en cualquier otras aplicaciones) utilizaremos el ~lenguaje de
probabilidad~ para ~expresar incertidumbre~ (citep:Jaynes2003). En este enfoque, es usual considerar
incertidumbre aleatoria. Por otro lado, un curso como el de cálculo numérico nos
permitirá cuantificar la incertidumbre epistémica. Sin embargo, también veremos
en este curso que con herramientas probabilísticas podemos cuantificar ciertas
nociones de incertidumbre de ambos tipos.


* Notación

Denotamos por $x$ una ~variable aleatoria~ y por $\mathbb{P}(\cdot)$ una ~función
de distribución~. Escribimos $x \sim \mathbb{P}$ para denotar que la variable
aleatoria $x$ tiene distribución $\mathbb{P}(\cdot)$. Denotamos por
$\mathbb{E}[\cdot]$ el ~valor esperado~ del argumento con respecto a la
distribución que estamos considerando. Durante el curso seremos explícitos en la
variable aleatoria y usaremos
\begin{align}
\mathbb{E}_x[\cdot] = \int_\mathcal{X} \cdot \, \pi(x) \, \text{d}x\,,
\end{align}
o bien, haremos énfasis en la distribución por medio de lo siguiente
\begin{align}
\mathbb{E}_\pi[\cdot] = \int_\mathcal{X} \cdot \, \pi(x) \, \text{d}x\,,
\end{align}
de acuerdo al contexto. 


#+BEGIN_NOTES
Nota que en las ecuaciones anteriores estamos considerando el término
$\pi(\cdot)$ como la ~función de densidad~ de la ~función de probabilidad~
$\mathbb{P}(\cdot)$.
#+END_NOTES

#+REVEAL: split
Nos será útil la siguiente notación para evaluar valores esperados
\begin{align}
\pi(f)  := \mathbb{E}_\pi[f(x)] = \int_\mathcal{X} f(x) \, \pi(x) \, \text{d}x\,,
\end{align}
pues será el ~objetivo general~ para los métodos que estudiaremos en el curso. 

#+REVEAL: split
Por ejemplo, utilizaremos la noción de ~aproximar integrales~ por medio de algún
procedimiento de muestreo de tal forma que esperaremos construir un estimación
$\hat \pi (f)$ con cierto grado de refinamiento. Por ejemplo, veremos el ~método
Monte Carlo~ que utiliza una colección de $N$ simulaciones para aproximar la
integral anterior. Esto lo denotaremos por
\begin{align}
\hat \pi_{N}^{\mathsf{MC}} (f) \approx \pi(f)\,. 
\end{align}


#+REVEAL: split
En general, nos interesa, y esperamos que, podamos: 
1. Mejorar nuestra estimación con mas muestras (simulaciones)
   \begin{align}
   \lim_{N \rightarrow \infty} \hat \pi_{N}^{\mathsf{MC}} (f) = \pi(f)\,
   \end{align}
2. Cuantificar la incertidumbre en nuestra aproximación por medio de alguna distribución de probabilidad. Por ejemplo,
   \begin{align}
   \hat \pi_{N}^{\mathsf{MC}} (f) \sim \mathsf{N}\left( \pi(f), \frac{\mathbb{V}(f)}{N} \right)\,.
   \end{align}


* Repaso de probabilidad

Consideraremos como requisitos el contenido de ~Cálculo de Probabilidades II~ y
~Álgebra Lineal~ (o equivalentes). En particular lo que requerimos como base es lo siguiente.

#+attr_latex: :options [Espacio de probabilidad]
#+begin_definition
Un espacio de probabilidad está definido por la terna $(\Omega, \mathcal{X}, \mathbb{P})$:
1. El espacio muestral, $\Omega$ (elementos). 
2. El espacio de eventos medibles, $\mathcal{X}$ (subconjuntos). 
3. La medida de probabilidad, $\mathbb{P}: \mathcal{X} \rightarrow [0, 1]$. 
#+end_definition

#+attr_latex: :options [Variable aleatoria]
#+begin_definition
Una variable aleatoria es una función $X:
\mathcal{X} \rightarrow \mathbb{R}$ con la propiedad de que las pre-imágenes
bajo $X$ son eventos medibles. Es decir,
\begin{align}
\{w \in \mathcal{X} : X(w) \leq x \} \in \mathcal{X} \qquad \forall x \in \mathbb{R}. 
\end{align}   
#+end_definition

#+attr_latex: :options [Función de acumulación de probabilidad]
#+begin_definition 
Para toda variable aleatoria $X$ tenemos una función de acumulación
$\mathbb{P}_{_X}: \mathbb{R} \rightarrow [0, 1]$ dada por
\begin{align}
\mathbb{P}_{_X}(x) = \mathbb{P} \big( \{w \in \mathcal{X} : X(w) \leq x\} \big)\,.
\end{align}
Esto usualmente lo escribimos como $\mathbb{P}_{_X}(x) = \mathbb{P}\{X \leq x\}$. 
#+end_definition

#+attr_latex: :options [Función de densidad]
#+begin_definition
Una variable aleatoria es continua si su función de acumulación es ~absolutamente
continua~ y puede ser expresada por medio de
\begin{align}
\mathbb{P}_{_X} (x) = \int_{- \infty}^x \pi (s) \, \text{d}s\,, 
\end{align}
donde la anti-derivada $\pi:\mathbb{R} \rightarrow [0, \infty)$ se llama la ~función de
densidad~ de la variable aleatoria $X$. 
#+end_definition

#+REVEAL: split
Las propiedades generales de las distribuciones de probabilidad se pueden
especificar por medio de su centralidad (localización), su dispersión, su rango
de valores, su simetría y el comportamiento de valores extremos.

#+REVEAL: split
En general esto lo podemos extraer de los momentos
\begin{align}
\mathbb{E}(X^p) = \int_{\mathbb{R}}^{} x^p \, \pi(x) \, \text{d}x\,,
\end{align}
o los momentos centrales. Por ejemplo: media y varianza. 

#+REVEAL: split
Uno de los resultados que espero recuerden bien de sus cursos anteriores es el
de la ~Ley de los Grandes Números~. La cual podemos enunciar como:

#+attr_latex: :options [Ley de los grandes números]
#+begin_theorem
Sea $X_1, X_2, \ldots$ una colección de variables aleatorias independientes e
idénticamente distribuidas ($\mathsf{iid}$) y sea $\bar X_n$ el promedio de un
subconjunto de $n$.  Si denotamos por $\mu$ el valor promedio de $X_i$
dentro de esa colección, entonces tenemos que
\begin{align}
\bar X_n  \rightarrow \mu \quad (\text{casi seguramente})\,.
\end{align}
#+end_theorem


#+ATTR_LATEX: :options [Límite Central]
#+begin_theorem 
Sea $X_1, \ldots, X_n$ una colección de $n$ variables aleatorias $\mathsf{iid}$
con $\mathbb{E}[X_i] = \mu$ y $\mathbb{V}[X_i] = \sigma^2 < \infty$. Entonces
tenemos que el comportamiento del promedio sigue la siguiente distribución
\begin{align}
\bar X_n \sim \mathsf{N}\left( \mu, \frac{\sigma^2}{n} \right)\,,
\end{align}
para $n$ suficientemente grande. 
#+end_theorem

* Conclusiones

En este curso estudiaremos las aproximaciones numéricas a problemas de
integración y optimización utilizando herramientas estocásticas (basadas en
variables aleatorias).

#+REVEAL: split
Cuantificar la incertidumbre de nuestras aproximaciones numéricas nos permite
utilizar variables aleatorias para caracterizar dicha incertidumbre. Esto nos
permite propagar incertidumbre a lo largo de todo un proceso de toma de
decisiones.

#+REVEAL: split
Las ventajas de esta metodología (simulación estocástica) son:

1. utilizar probabilidad para caracterizar escenarios posibles;
2. utilizar nuestras computadoras para realizar dichas simulaciones; 
3. determinar hasta qué momento estamos satisfechos con nuestra aproximación. 

bibliographystyle:abbrvnat
bibliography:references.bib
